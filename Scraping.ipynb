{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "parliamentary-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bound-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Arjun Tendulkar', 'Bowling Allrounder • India', 'SOLD', 'Base Price 20.00', 'Lakh', 'Final Price 20.00', 'Lakh', 'Sold To MI', '']\n"
     ]
    }
   ],
   "source": [
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "       'Accept-Encoding': 'none',\n",
    "       'Accept-Language': 'en-US,en;q=0.8',\n",
    "       'Connection': 'keep-alive'}\n",
    "\n",
    "# url = input('Enter - ')\n",
    "url = 'https://www.cricbuzz.com/cricket-series/ipl-2021/auction/completed'\n",
    "\n",
    "\n",
    "req = urllib.request.Request(url, headers=hdr)\n",
    "page = urllib.request.urlopen(req, context=ctx)\n",
    "html = page.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "lst = list()\n",
    "tags = soup('a')\n",
    "\n",
    "raw_data = list()\n",
    "link=\"cb-col cb-col-100 cb-font-14 text-center\"\n",
    "\n",
    "div = soup.find_all('a', {\"class\" : link})\n",
    "for d in div:\n",
    "    raw_data.append(re.split(r'\\s{2,}', d.text))\n",
    "    \n",
    "print(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessory-butterfly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = list()\n",
    "speciality = list()\n",
    "country = list()\n",
    "status = list()\n",
    "base_price = list()\n",
    "final_price = list()\n",
    "team = list()\n",
    "\n",
    "for plyr in raw_data:\n",
    "    x = plyr[2].split(\"•\")\n",
    "    if len(x) > 1: \n",
    "        name.append(plyr[1])\n",
    "        speciality.append(x[0])\n",
    "        country.append(x[1])\n",
    "\n",
    "        bs = int(float(plyr[4].split(\" \")[2]))\n",
    "        if plyr[5] == \"Crore\": bs *= 100\n",
    "        base_price.append(bs)\n",
    "         \n",
    "        status.append(plyr[3])\n",
    "        if plyr[3] == 'SOLD':\n",
    "            fp = int(float(plyr[6].split(\" \")[2]))\n",
    "            if plyr[7] == \"Crore\": fp *= 100\n",
    "            final_price.append(fp)    \n",
    "            team.append(plyr[8].split()[2])\n",
    "        else:\n",
    "            final_price.append('-')\n",
    "            team.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlimited-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name': name,\n",
    "                   'Role': speciality,\n",
    "                   'Country': country,\n",
    "                   'Status': status,\n",
    "                   'Base_Price(Lakh)': base_price,\n",
    "                   'Final_Price(Lakh)': final_price,\n",
    "                   'Team': team})\n",
    "\n",
    "df.to_csv('auction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "undefined-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_link = list()\n",
    "\n",
    "for n in name:\n",
    "    if len(n.split()) > 1:\n",
    "        url = f'https://search.espncricinfo.com/ci/content/site/search.html?search=+{n.split()[0]}%20+{n.split()[1]};type=player'\n",
    "\n",
    "\n",
    "        req = urllib.request.Request(url, headers=hdr)\n",
    "        page = urllib.request.urlopen(req, context=ctx)\n",
    "        html = page.read()\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        tags = soup('a')\n",
    "\n",
    "        i=0\n",
    "        for tag in tags:\n",
    "            if 'player' in tag.get('href', None):\n",
    "                i += 1\n",
    "                if  i % 3 == 0: \n",
    "                    player_link.append(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "limited-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "raising-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/india/content/player/1148776.html'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_link[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bizarre-communication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mat', 'Inns', 'NO', 'Runs', 'HS', 'Ave', 'BF', 'SR', '100', '50', '4s', '6s', 'Ct', 'St', 'T20s', '2', '2', '1', '3', '3', '3.00', '7', '42.85', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.espncricinfo.com'\n",
    "\n",
    "url = base_url + player_link[0]\n",
    "\n",
    "req = urllib.request.Request(url, headers=hdr)\n",
    "page = urllib.request.urlopen(req, context=ctx)\n",
    "html = page.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "raw_data = list()\n",
    "link='engineTable'\n",
    "\n",
    "table = soup.find('table', {\"class\" : link})\n",
    "print(table.text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-apparel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
